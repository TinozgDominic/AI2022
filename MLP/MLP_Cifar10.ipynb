{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOvV1u+JzTyWgOfUyb7SYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TinozgDominic/AI2022/blob/main/MLP/MLP_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "kJIh_OHbS35Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "z0DXpSQI7g9E"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(f'Input shape: {x_train[0].shape}')\n",
        "print(f'Output shape: {y_train[0].shape}')\n",
        "print(f'Train size: {len(x_train)}')\n",
        "print(f'Test size: {len(x_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1rRulaC75Qj",
        "outputId": "6741a3dd-5ed2-42a3-c766-0c950c8259db"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (32, 32, 3)\n",
            "Output shape: (1,)\n",
            "Train size: 50000\n",
            "Test size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.image.rgb_to_grayscale(x_train)\n",
        "x_test = tf.image.rgb_to_grayscale(x_test)\n",
        "\n",
        "print(f'Input shape: {x_train[0].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RiZfnsh-p8c",
        "outputId": "e3e5c37f-2693-4f5c-cec9-6f6d466bdd28"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (32, 32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "vL1Da0Wh8owP"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Output shape: {y_train[0].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smC1Yz1b9MX0",
        "outputId": "57cee1f7-ad7f-44b2-b1c8-975d5009fc69"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape = [32,32,1]))\n",
        "model.add(layers.Dense(500, activation = 'relu'))\n",
        "model.add(layers.Dense(300, activation = 'relu'))\n",
        "model.add(layers.Dense(100, activation = 'relu'))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IOwl-Jb8Bfm",
        "outputId": "09aac9a7-e5ba-43f7-e8a3-a33a22a72313"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 500)               512500    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 693,910\n",
            "Trainable params: 693,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
        "\n",
        "callbacks = [Callback(), \n",
        "            EarlyStopping(patience=21, verbose=1),\n",
        "            ReduceLROnPlateau(patience=5, verbose=1),\n",
        "            ModelCheckpoint('MLP_Cifar10.h5', verbose=1, save_best_only=True)]"
      ],
      "metadata": {
        "id": "k_ngdwmM8TAy"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs = 100, batch_size = 500,validation_data=(x_test, y_test), callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goOSMFxu8cY6",
        "outputId": "4384441e-3ff7-4d86-e5e4-a031112b1511"
      },
      "execution_count": 150,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5459 - accuracy: 0.4613\n",
            "Epoch 1: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3796 - lr: 1.0000e-08\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5453 - accuracy: 0.4609\n",
            "Epoch 2: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3796 - lr: 1.0000e-08\n",
            "Epoch 3/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5448 - accuracy: 0.4613\n",
            "Epoch 3: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-08\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4613\n",
            "Epoch 4: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-08\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4613\n",
            "Epoch 5: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-08\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4613\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4613 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-08\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5443 - accuracy: 0.4618\n",
            "Epoch 7: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-09\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 8: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-09\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 9: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-09\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5452 - accuracy: 0.4614\n",
            "Epoch 10: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-09\n",
            "Epoch 11/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5465 - accuracy: 0.4611\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-09\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 12: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-10\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5458 - accuracy: 0.4610\n",
            "Epoch 13: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-10\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 14: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-10\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 15: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-10\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5448 - accuracy: 0.4616\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-10\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5455 - accuracy: 0.4613\n",
            "Epoch 17: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-11\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.4612\n",
            "Epoch 18: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 6s 61ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-11\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 19: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-11\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4612\n",
            "Epoch 20: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-11\n",
            "Epoch 21/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.4608\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-11\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5450 - accuracy: 0.4615\n",
            "Epoch 22: val_loss did not improve from 1.76921\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 1.5454 - accuracy: 0.4612 - val_loss: 1.7709 - val_accuracy: 0.3795 - lr: 1.0000e-12\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5924362b50>"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', \n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "OJJHPEq-EtWf"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "show = random.randint(0,9999)\n",
        "\n",
        "print('Predict:',classes[np.argmax(model.predict(x_test[show]))])\n",
        "print('True mask:',classes[np.argmax(y_test[show])])\n",
        "\n",
        "plt.imshow(tf.reshape(x_test[show],[32,32]))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "G4hoa24JYSDC",
        "outputId": "2bee6007-b6ea-4b26-af2c-a65ba2abd487"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predict: frog\n",
            "True mask: frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}